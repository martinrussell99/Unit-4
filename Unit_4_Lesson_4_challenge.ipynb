{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import inaugural, state_union, stopwords\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\Martin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\Martin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('inaugural')\n",
    "nltk.download('state_union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1945-Truman.txt', '1946-Truman.txt', '1947-Truman.txt', '1948-Truman.txt', '1949-Truman.txt', '1950-Truman.txt', '1951-Truman.txt', '1953-Eisenhower.txt', '1954-Eisenhower.txt', '1955-Eisenhower.txt', '1956-Eisenhower.txt', '1957-Eisenhower.txt', '1958-Eisenhower.txt', '1959-Eisenhower.txt', '1960-Eisenhower.txt', '1961-Kennedy.txt', '1962-Kennedy.txt', '1963-Johnson.txt', '1963-Kennedy.txt', '1964-Johnson.txt', '1965-Johnson-1.txt', '1965-Johnson-2.txt', '1966-Johnson.txt', '1967-Johnson.txt', '1968-Johnson.txt', '1969-Johnson.txt', '1970-Nixon.txt', '1971-Nixon.txt', '1972-Nixon.txt', '1973-Nixon.txt', '1974-Nixon.txt', '1975-Ford.txt', '1976-Ford.txt', '1977-Ford.txt', '1978-Carter.txt', '1979-Carter.txt', '1980-Carter.txt', '1981-Reagan.txt', '1982-Reagan.txt', '1983-Reagan.txt', '1984-Reagan.txt', '1985-Reagan.txt', '1986-Reagan.txt', '1987-Reagan.txt', '1988-Reagan.txt', '1989-Bush.txt', '1990-Bush.txt', '1991-Bush-1.txt', '1991-Bush-2.txt', '1992-Bush.txt', '1993-Clinton.txt', '1994-Clinton.txt', '1995-Clinton.txt', '1996-Clinton.txt', '1997-Clinton.txt', '1998-Clinton.txt', '1999-Clinton.txt', '2000-Clinton.txt', '2001-GWBush-1.txt', '2001-GWBush-2.txt', '2002-GWBush.txt', '2003-GWBush.txt', '2004-GWBush.txt', '2005-GWBush.txt', '2006-GWBush.txt']\n"
     ]
    }
   ],
   "source": [
    "print(state_union.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdrfilenames = ['1933-Roosevelt.txt', '1937-Roosevelt.txt', '1941-Roosevelt.txt', '1945-Roosevelt.txt']\n",
    "rrfilenames = ['1981-Reagan.txt', '1985-Reagan.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fdr.txt\", \"w\") as f:\n",
    "    for filename in fdrfilenames:\n",
    "        f.write(nltk.corpus.inaugural.raw(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rr.txt\", \"w\") as f:\n",
    "    for filename in rrfilenames:\n",
    "        f.write(nltk.corpus.inaugural.raw(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fdr.txt', 'r') as myfile:\n",
    "    Roosevelt = myfile.read()\n",
    "with open('rr.txt', 'r') as myfile:\n",
    "    Reagan = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reaganclean = re.sub(\"\\n\", \"\", Reagan)\n",
    "Reaganclean = re.sub(\"--\", \" \", Reaganclean)\n",
    "Reagan = Reaganclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rooseveltclean = re.sub(\"\\n\", \"\", Roosevelt)\n",
    "Rooseveltclean = re.sub(\"--\", \" \", Rooseveltclean)\n",
    "Roosevelt = Rooseveltclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "Reagan_doc = nlp(Reagan)\n",
    "Roosevelt_doc = nlp(Roosevelt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reagan_sents = [[sent, \"Reagan\"] for sent in Reagan_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Roosevelt_sents = [[sent, \"Roosevelt\"] for sent in Roosevelt_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.DataFrame(Reagan_sents + Roosevelt_sents)\n",
    "sentences_tfidf = pd.DataFrame(Reagan_sents + Roosevelt_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_count1 = sentences_tfidf.isnull().sum()\n",
    "null_count1[null_count1>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_used_words(text):\n",
    "    allwords = [token.lemma_ for token in text\n",
    "               if not token.is_punct and not token.is_stop]\n",
    "    return [item[0] for item in Counter(allwords).most_common(100)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_word_features(sentences, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        words = [token.lemma_\n",
    "                for token in sentence\n",
    "                if (\n",
    "                not token.is_punct\n",
    "                and not token.is_stop\n",
    "                and token.lemma_ in common_words\n",
    "                )]\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "            \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Reaganwords = most_used_words(Reagan_doc)\n",
    "Rooseveltwords = most_used_words(Roosevelt_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidential_words = set(Reaganwords + Rooseveltwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = common_word_features(sentences, presidential_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>growth</th>\n",
       "      <th>effort</th>\n",
       "      <th>free</th>\n",
       "      <th>sacred</th>\n",
       "      <th>call</th>\n",
       "      <th>dream</th>\n",
       "      <th>action</th>\n",
       "      <th>tax</th>\n",
       "      <th>strength</th>\n",
       "      <th>...</th>\n",
       "      <th>civilization</th>\n",
       "      <th>hope</th>\n",
       "      <th>measure</th>\n",
       "      <th>hero</th>\n",
       "      <th>think</th>\n",
       "      <th>great</th>\n",
       "      <th>value</th>\n",
       "      <th>economic</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Senator, Hatfield, ,, Mr., Chief, Justice, ,,...</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, orderly, transfer, of, authority, as, ca...</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(In, the, eyes, of, many, in, the, world, ,, t...</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Mr, .)</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(President, ,, I, want, our, fellow, citizens,...</td>\n",
       "      <td>Reagan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  -PRON- growth effort free sacred call dream action tax strength     ...      \\\n",
       "0      0      0      0    0      0    0     0      0   0        0     ...       \n",
       "1      0      0      0    0      0    1     0      0   0        0     ...       \n",
       "2      0      0      0    0      0    0     0      0   0        0     ...       \n",
       "3      0      0      0    0      0    0     0      0   0        0     ...       \n",
       "4      1      0      0    0      0    0     0      0   0        0     ...       \n",
       "\n",
       "  civilization hope measure hero think great value economic  \\\n",
       "0            0    0       0    0     0     0     0        0   \n",
       "1            0    0       0    0     1     0     0        0   \n",
       "2            0    0       0    0     0     0     0        0   \n",
       "3            0    0       0    0     0     0     0        0   \n",
       "4            0    0       0    0     0     0     0        0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Senator, Hatfield, ,, Mr., Chief, Justice, ,,...      Reagan  \n",
       "1  (The, orderly, transfer, of, authority, as, ca...      Reagan  \n",
       "2  (In, the, eyes, of, many, in, the, world, ,, t...      Reagan  \n",
       "3                                            (Mr, .)      Reagan  \n",
       "4  (President, ,, I, want, our, fellow, citizens,...      Reagan  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(presidential_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8591885441527446\n",
      "\n",
      "Test set score: 0.7047619047619048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate our model and fit the data.\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2,random_state=0)\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X_train, y_train)\n",
    "print('Training set score:', svm.score(X_train, y_train))\n",
    "print('\\nTest set score:', svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Reagan</th>\n",
       "      <th>Roosevelt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reagan</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roosevelt</th>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        Reagan  Roosevelt\n",
       "text_source                   \n",
       "Reagan           39         13\n",
       "Roosevelt        18         35"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_predicted = svm.predict(X_test)\n",
    "pd.crosstab(y_test, svm_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences_tfidf.rename(columns={0: \"a\", 1: \"b\"})\n",
    "#sentences_tfidf[0] = sentences_tfidf[0].astype(int).astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef custom_tokenize(text):\\n    if not text:\\n        print('The text to be tokenized is a None type. Defaulting to blank string.')\\n        text = ''\\n    return word_tokenize(text)\\nsentences_tfidf['a'] = sentences_tfidf.a.apply(custom_tokenize)\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def custom_tokenize(text):\n",
    "    if not text:\n",
    "        print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
    "        text = ''\n",
    "    return word_tokenize(text)\n",
    "sentences_tfidf['a'] = sentences_tfidf.a.apply(custom_tokenize)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en')\n",
    "#emma = ' '\n",
    "#emma = emma.join(emma_paras)\n",
    "sentences_tfidf.loc[sentences_tfidf[1] == 'Reagan', 1] = 1\n",
    "sentences_tfidf.loc[sentences_tfidf[1] == 'Roosevelt', 1] = 0\n",
    "\n",
    "sentences_tfidf_X = sentences_tfidf[0]\n",
    "sentences_tfidf_y = sentences_tfidf[1]\n",
    "##emma = [[sent, 'emma']for sent in emma.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tfidf_y = sentences_tfidf_y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Senator Hatfield, Mr. Chief Justice, Mr. President, Vice President Bush, Vice President Mondale, Senator Baker, Speaker O'Neill, Reverend Moomaw, and my fellow citizens: To a few of us here today, this is a solemn and most momentous occasion; and yet, in the history of our Nation, it is a commonplace occurrence.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(sentences_tfidf_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(sentences_tfidf_X, sentences_tfidf_y, test_size=0.4, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=False, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             #norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             #smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "#X_train_tfidf = X_train_tfidf.apply(lambda x:x.text)\n",
    "#X_test_tfidf = X_test_tfidf.apply(lambda x:x.text)\n",
    "sentences_tfidf_X = sentences_tfidf_X.apply(lambda x:x.text)\n",
    "\n",
    "#Applying the vectorizer\n",
    "sentences_tfidf_X = vectorizer.fit_transform(sentences_tfidf_X)\n",
    "#X_train_tfidf=vectorizer.fit_transform(X_train_tfidf)\n",
    "#X_test_tfidf=vectorizer.fit_transform(X_test_tfidf)\n",
    "\n",
    "#print(\"Number of features: %d\" % sentences_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "#X_train_tfidf, X_test_tfidf= train_test_split(sentences_tfidf, test_size=0.4, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVectorizer.fit_transform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "5      1\n",
       "6      1\n",
       "7      1\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     1\n",
       "13     1\n",
       "14     1\n",
       "15     1\n",
       "16     1\n",
       "17     1\n",
       "18     1\n",
       "19     1\n",
       "20     1\n",
       "21     1\n",
       "22     1\n",
       "23     1\n",
       "24     1\n",
       "25     1\n",
       "26     1\n",
       "27     1\n",
       "28     1\n",
       "29     1\n",
       "      ..\n",
       "494    0\n",
       "495    0\n",
       "496    0\n",
       "497    0\n",
       "498    0\n",
       "499    0\n",
       "500    0\n",
       "501    0\n",
       "502    0\n",
       "503    0\n",
       "504    0\n",
       "505    0\n",
       "506    0\n",
       "507    0\n",
       "508    0\n",
       "509    0\n",
       "510    0\n",
       "511    0\n",
       "512    0\n",
       "513    0\n",
       "514    0\n",
       "515    0\n",
       "516    0\n",
       "517    0\n",
       "518    0\n",
       "519    0\n",
       "520    0\n",
       "521    0\n",
       "522    0\n",
       "523    0\n",
       "Name: 1, Length: 524, dtype: int32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_tfidf_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_tfidf = y_train_tfidf.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(sentences_tfidf_X, sentences_tfidf_y, test_size=0.4, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tfidfing set score: 0.9745222929936306\n",
      "\n",
      "test_tfidf set score: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate our model and fit the data.\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "#X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_tfidf_test_tfidf_split(X, Y,test_tfidf_size=0.2,random_state=0)\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X_train_tfidf, y_train_tfidf)\n",
    "print('train_tfidfing set score:', svm.score(X_train_tfidf, y_train_tfidf))\n",
    "print('\\ntest_tfidf set score:', svm.score(X_test_tfidf, y_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   0   1\n",
       "1            \n",
       "0      82  22\n",
       "1      41  65"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_predicted = svm.predict(X_test_tfidf)\n",
    "pd.crosstab(y_test_tfidf, svm_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
